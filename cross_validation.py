# -*- coding: utf-8 -*-
"""cross validation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uP-TZtZzK3O4192fHyLcnIY6UNC4tlXy
"""

import numpy as np
from sklearn.model_selection import cross_val_score, KFold
from sklearn.naive_bayes import GaussianNB
from sklearn import preprocessing
from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score

# IMDb dataset
movie = ['sita ramam', 'rrr', 'fida', 'devdas', 'jeans', 'sir', 'hello', 'anand', 'godavari', 'lion']
genre = ['historical drama', 'action', 'romance', 'action', 'comedy', 'action', 'romance', 'romance', 'romance', 'action']
rating = [9, 8, 6, 5, 8, 8, 9, 8.5, 7.9, 9.5]
review = ['Excellent', 'Very Good', 'Good', 'Average', 'Very Good', 'Very Good', 'Excellent', 'Very Good', 'Good', 'Excellent']
hit = ['yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes']

le = preprocessing.LabelEncoder()
me = le.fit_transform(movie)
genre = le.fit_transform(genre)
r = le.fit_transform(rating)
re = le.fit_transform(review)
label = le.fit_transform(hit)

features = []
for i in range(len(me)):
  features.append([me[i], genre[i], r[i], re[i]])

# Convert the feature and label lists to numpy arrays
features = np.array(features)
label = np.array(label)

# Initialize Naive Bayes classifier
model = GaussianNB()

# Perform 10-fold cross-validation
kfold = KFold(n_splits=10, shuffle=True, random_state=42)

# Initialize lists to store evaluation scores
accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores = []

for train_index, test_index in kfold.split(features):
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]

    # Train the classifier
    model.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = model.predict(X_test)

    # Calculate evaluation scores
    accuracy = model.score(X_test, y_test)
    accuracy_scores.append(accuracy)

    # Calculate precision, recall, and F1-score, handling zero division
    precision = precision_score(y_test, y_pred, zero_division=1)
    recall = recall_score(y_test, y_pred, zero_division=1)
    f1 = f1_score(y_test, y_pred, zero_division=1)

    # Append the scores to the lists
    accuracy_scores.append(accuracy)
    precision_scores.append(precision)
    recall_scores.append(recall)
    f1_scores.append(f1)

# Calculate average scores over all folds
avg_accuracy = np.mean(accuracy_scores)
avg_precision = np.mean(precision_scores)
avg_recall = np.mean(recall_scores)
avg_f1 = np.mean(f1_scores)

# Print average scores
print("Average Accuracy:" ,avg_accuracy)
print("Average Precision: ",avg_precision)
print("Average Recall: ",avg_recall)
print("Average F1-score:",avg_f1)